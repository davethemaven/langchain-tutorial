{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a0ea0c4-7dd9-4ed8-9385-7349ae4586f2",
   "metadata": {},
   "source": [
    "# Tools involved\n",
    "\n",
    "## LangSmith\n",
    "LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!\n",
    "\n",
    "## GitHub\n",
    "GitHub is a platform for version control and collaboration, allowing developers to manage and share code repositories. It integrates with Git, a distributed version control system, to track changes, manage branches, and collaborate on software projects. GitHub also provides features like issue tracking, pull requests, and project management tools to streamline development workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e0ec66-905a-4f2f-a7c0-4bc3c45f0e61",
   "metadata": {},
   "source": [
    "## Things I installed\n",
    "```pip install langchain```\n",
    "\n",
    "```pip install -U langsmith```\n",
    "\n",
    "```pip install -qU langchain-openai```\n",
    "\n",
    "# Environment variables\n",
    "instead of putting the API keys in the notebook, it's best practice to not share or expose those variables.  In the tutorial, it mentions you can have them imported directly in the notebook but I chose to go with a .env file.  I'm also going to add it to the '.gitignore' file.\n",
    "\n",
    "## Summary of Steps\n",
    "1. Create a .env file with your environment variables.\n",
    "2. Install the python-dotenv package.\n",
    "3. Load the .env file in your Python script or notebook using load_dotenv().\n",
    "4. Access the environment variables with os.getenv().\n",
    "\n",
    "By following these steps, you can securely manage and use environment variables from a .env file in your Python projects. Let me know if you have any further questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "546924b9-9fd0-4f2d-b123-716721d166fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Now we can access the variables as usual\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "langchain_tracing_v2 = os.getenv(\"LANGCHAIN_TRACING_V2\")\n",
    "langchain_api_key = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4\", openai_api_key = openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0bb5b5de-d2d9-4d00-86e8-5e806bd6ab71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ciao!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 20, 'total_tokens': 23}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_507c9469a1', 'finish_reason': 'stop', 'logprobs': None}, id='run-6e1f35c0-31dc-4780-9628-351101722f77-0', usage_metadata={'input_tokens': 20, 'output_tokens': 3, 'total_tokens': 23})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"Translate the following from English into Italian\"),\n",
    "    HumanMessage(content=\"hi!\"),\n",
    "]\n",
    "\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503e6691-44c0-4472-b1bb-bb8a0f88f13e",
   "metadata": {},
   "source": [
    "# Explanation of the Above Cell\n",
    "We're priming the AI through the SystemMessage, to translate whatever the human says, through the HumanMessage, to Italian.  We're then invoking it\n",
    "## Langchain_core.messages\n",
    "### HumaMessage\n",
    "[Docs](https://api.python.langchain.com/en/latest/messages/langchain_core.messages.human.HumanMessage.html)\n",
    "\n",
    "Message from a human.\n",
    "\n",
    "HumanMessages are messages that are passed in from a human to the model.\n",
    "\n",
    "### SystemMessage\n",
    "[Docs](https://api.python.langchain.com/en/latest/messages/langchain_core.messages.system.SystemMessage.html)\n",
    "\n",
    "Message for priming AI behavior.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2b49d21-2bc9-4a5d-a1da-3dbcac221482",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f53d71a-0830-4ddc-a874-c620736d0564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ciao!'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This cell shows that we can take the message and use the parser to only share the \n",
    "# result.  Rather than sharing all of the other metadata as well.\n",
    "result = model.invoke(messages)\n",
    "parser.invoke(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9ef7799-54ee-4941-9fb3-249d0dc278e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ciao!'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This cell goes through the \"chain\" concept.  The way I understand it, we\n",
    "# create a chain and then can invoke the message in the same way moving forward.\n",
    "# Since we set the parser to StrOutputParser(), it just shares the string.\n",
    "chain = model | parser\n",
    "chain.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f03a1f21-67af-4492-89b4-60f5006c5988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we're creating a PromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# This is a string that will be the system message.  We can input different\n",
    "# languages by having it set to {language}\n",
    "system_template = \"Translate the following into {language}:\"\n",
    "\n",
    "# This prompt template will get the user input and apply it to {text}\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "189afc26-527f-4336-8908-0312d78a0305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Translate the following into italian:'), HumanMessage(content='hi')])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = prompt_template.invoke({\"language\": \"italian\", \"text\": \"hi\"})\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "56df4cb4-4960-4dc9-bc93-af3fd8327b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Translate the following into italian:'),\n",
       " HumanMessage(content='hi')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2d4e80aa-0017-4c6b-8bc4-37f98d1f1d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt_template | model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "401a96a2-fd5d-42fb-9994-dbcefef93a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ciao'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"language\": \"italian\", \"text\": \"hi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6336226a-8c14-4b4f-8580-0714243caeae",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2065073899.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    python serve.py\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5d9a00-58e5-449e-b8f8-a25678cbf468",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
